{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 3_PrácticoIAA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcAYqmos4O26ogzvd46Owl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caropilardiaz/Mentoria-Imagenes_Drones/blob/master/3_Pr%C3%A1cticoIAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzPhzP2fpt0Q",
        "colab_type": "text"
      },
      "source": [
        "##**Diplomatura en Ciencias de Datos, Aprendizaje Automático y sus Aplicaciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTY7X_KSo9ay",
        "colab_type": "text"
      },
      "source": [
        "##**Mentoría Diplomatura en Ciencia de Datos 2020**\n",
        "###**\"Detección del desarrollo del cultivo con imágenes de Drones\"**\n",
        "###**Mentora**: Carolina Del Pilar Díaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-UmQ4fCqTMj",
        "colab_type": "text"
      },
      "source": [
        "###**Introducción al Aprendizaje Automático**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EZ_J-LBn8ha",
        "colab_type": "text"
      },
      "source": [
        " \n",
        "En este laboratorio deben hacer experimentos de regresión y clasificación con el conjunto de datos obtenido en el práctico anterior.\n",
        "\n",
        "Estudiarán el dataset y seleccionarán atributos relevantes a mano. \n",
        "\n",
        "El objetivo consiste en explorar la aplicación de diferentes métodos de aprendizaje supervisado aprendidos en el curso, a través de experimentos reproducibles, y evaluando a su vez la conveniencia de uno u otro, así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes. Nuestro objetivo no será construir el mejor modelo, sino ganar un poco más de intuición sobre nuestro conjunto de datos, y tomar algunas decisiones sobre las que profundizaremos en el próximo práctico.\n",
        "\n",
        "Luego, entrenarán y evaluarán diferentes tipos de regresiones y clasificadores, buscando las configuraciones que mejores resultados den."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPiXCvZi-f1x",
        "colab_type": "text"
      },
      "source": [
        "###Preprocesamiento\n",
        "Antes de aplicar los modelos, haremos un filtrado de los datos. Se sugiere seguir los siguientes pasos, pero pueden experimentar ustedes también otras alternativas.ZADOCK y RDTO serán nuestras variables objetivos, sobre la cual buscaremos hacer predicciones las cuáles poseen diferentes distribuciones.\n",
        "\n",
        "###Crear los siguientes features:\n",
        "Ciclos; Asignar el valor 0 al ciclo corto y valor 1 al ciclo largo.\n",
        "Conjunto de datos; Variable binaria construida a partir de asignar 1 correspondiente a la 1° fecha de siembra, o 0 en caso contrario.\n",
        "Pueden decidir otras configuraciones que necesiten.\n",
        "\n",
        "###Recordar;\n",
        "Una vez que el dataset resultante no tenga valores nulos, es necesario transformar las variables categóricas en variables numéricas (es decir, realizar un encoding de los datos) además de convertir longitud,latitud y fechas a numericas.\n",
        "\n",
        "Más info https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ufZGp_krsB",
        "colab_type": "text"
      },
      "source": [
        "###Elección de los modelos\n",
        "Con los pasos anteriores, nuestro dataset debería ser una tabla con valores numéricos y sin valores nulos. Ahora, deberán separar el conjunto de datos en conjunto de entrenamiento (train) y conjunto de prueba (test). Por ahora, no utilizaremos conjunto de validación. Se recomienda utilizar el método train_test_split de scikitlearn, con un 80% para train y 20% para test.\n",
        "\n",
        "Una vez divididos los datos, construimos los modelos predictivos. Entrenen cada modelo utilizando el conjunto de entrenamiento y los parámetros por defecto y evaluen la predicción utilizando las cinco métricas descriptas más adelante según corresponda al modelo. \n",
        "\n",
        "Es importante recordar, que el dataset posee dos targets con distribuciones diferentes, ZADOK y RDTO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3d_7I9ObBGS",
        "colab_type": "text"
      },
      "source": [
        "###Elección de métricas\n",
        "Un aspecto fundamental del aprendizaje automático es la elección de métricas para evaluar los modelos predictivos según correspondan. En este práctico vamos a explorar las siguientes cinco métricas:\n",
        "ECM, \n",
        "Accuracy,\n",
        "F1\n",
        "AUC ROC,\n",
        "AUC Precision-Recall.\n",
        "\n",
        "Para cada uno de los modelos que utilicen, calculen las cinco métricas. Pueden encontrar información sobre las últimas dos https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F3rmd38b1oN",
        "colab_type": "text"
      },
      "source": [
        "###División en Entrenamiento y Evaluación\n",
        "Dividimos aleatoriamente los datos en 80% para entrenamiento y 20% para evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ptGChrFhDhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trkhbmCab02P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5yj2Jpvdbee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpqAOvQEdcsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghDjKs7-fQ2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# División entre instancias y etiquetas\n",
        "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzNExedHqhOe",
        "colab_type": "text"
      },
      "source": [
        "###**1.Regresión**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOWkRyZao8Dx",
        "colab_type": "text"
      },
      "source": [
        "###**1.1.Regresión Lineal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJFbHuOojxfb",
        "colab_type": "text"
      },
      "source": [
        "Elegir un atributo para el target \"RDTO\", instancie una regresión lineal,evaluar ECM de train y test, grafique el modelo junto a los puntos de train y test.Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8hkX_-5lpL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature = ''  # selecciono el atributo ''\n",
        "selector = (dron['feature_names'] == feature)\n",
        "X_train_f = X_train[:, selector]\n",
        "X_test_f = X_test[:, selector]\n",
        "X_train_f.shape, X_test_f.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_GLf_Pum924",
        "colab_type": "text"
      },
      "source": [
        "###**1.2.Regresión Polinomial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKuJLJTnYmw",
        "colab_type": "text"
      },
      "source": [
        "En este ejercicio deben entrenar regresiones polinomiales de diferente complejidad, siempre usando scikit-learn.Deben usar el mismo atributo seleccionado para el ejercicio anterior.Instancie y entrene, prediga y calcule error train y test, imprima valores, guarde errores.\n",
        "Grafique las curvas de error en términos del grado del polinomio.\n",
        "Seleccione el modelo que mejor funcione, y grafique el modelo conjuntamente con los puntos.Interprete el resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1sUR5Q_on1v",
        "colab_type": "text"
      },
      "source": [
        "###**1.3.Regresión con más de un atributo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeHyqT_apQKH",
        "colab_type": "text"
      },
      "source": [
        "Seleccione dos o tres atributos entre los más relevantes.\n",
        "Repita el ejercicio anterior, pero usando los atributos seleccionados.\n",
        "Interprete el resultado y compare con los ejercicios anteriores. ¿Se obtuvieron mejores modelos? ¿Porqué?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRQqKlXxpgN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Con dos atributos fs:\n",
        "selector = (dron['feature_names'] == '') | (dron['feature_names'] == '')\n",
        "X_train_fs = X_train[:, selector]\n",
        "X_test_fs = X_test[:, selector]\n",
        "X_train_fs.shape, X_test_fs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_NLPt1Ep9QX",
        "colab_type": "text"
      },
      "source": [
        "###**1.4.Regresión múltiple. Completa**\n",
        "Entrene y evalúe regresiones pero utilizando todos los atributos de entrada (va a andar mucho más lento). Estudie los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFp8SfeXq87W",
        "colab_type": "text"
      },
      "source": [
        "###**1.5.Regularización**\n",
        "Utilizar diferentes valores de alpha. ¿Mejora?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqN_OEuzuAct",
        "colab_type": "text"
      },
      "source": [
        "###**2.Clasificación**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxhgYs3lzEC6",
        "colab_type": "text"
      },
      "source": [
        "###**2.1.SGDClassifier con selección de hiperparámetros**. \n",
        "Probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.Usar grid-search y 5-fold cross-validation. Reportar métricas y varianzas.Reportar accuracy promedio y varianza para todas las configuraciones, evaluar sobre el conjunto de entrenamiento y sobre el conjunto de evaluación, reportando:\n",
        "\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1\n",
        "matriz de confusión\n",
        "Documentación:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4zKiYJV0rcy",
        "colab_type": "text"
      },
      "source": [
        "###**2.2.DecisionTreeClassifier**. \n",
        "Idem anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38X2jvXz2Knj",
        "colab_type": "text"
      },
      "source": [
        "###**2.3.Random Forest**\n",
        "idem anterior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHNr_7-M0qbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.Predict(X_test)\n",
        "\n",
        "print('Accuracy score = ', accuracy_score(y_test, y_pred))\n",
        "print('F1 score = ', f1_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDZeBuBa3gFZ",
        "colab_type": "text"
      },
      "source": [
        "###**2.4. Responder**\n",
        "\n",
        "¿Qué diferencias hay entre los distintos modelos? ¿Qué tan buenas son las predicciones?\n",
        "\n",
        "Jueguen un poco variando algunos parámetros (no es necesario hacer una búsqueda sistemática). ¿Qué parámetros influyen más en el desempeño de los clasificadores? ¿Por qué les parece que algunos parámetros influyen más que otros?\n",
        "\n",
        "###**2.5.Normalizando los datos de entrada**\n",
        " (pueden usar, por ejemplo MinMaxScaler o StandardScaler). ¿Hay alguna diferencia en el resultado de los modelos? ¿A qué se debe?\n",
        "\n",
        "Finalmente, intenten mejorar las predicciones agregando o quitando features, o variando el tipo de encoding. En base a los resultados que vayan obteniendo, determinen los features que ustedes consideren que son más informativos (aquellos que ayudan a mejorar la predicción) y aquellos que sean redundantes, o que empeoren el resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3stfAjKrK5do",
        "colab_type": "text"
      },
      "source": [
        "###**3.Opcional**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIPoeK--LE1s",
        "colab_type": "text"
      },
      "source": [
        "###**3.1. Multinomial Naives Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rttdFxLdGD",
        "colab_type": "text"
      },
      "source": [
        "###**3.2. KNN**"
      ]
    }
  ]
}